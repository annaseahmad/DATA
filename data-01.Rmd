---
title: "[DATA-01] Data science with R"
author: "Miguel-Angel Canela, IESE Business School"
date: "June 14, 2016"
output: 
  html_document:
    toc: false
    theme: united
---
### What is data mining?

**Data mining** is a generic expression which applies to a heterogeneous set of methods, used to extract information from large data sets. The expression is understood as *mining knowledge from data*. Data mining methods are very popular nowadays, not because there are a real innovation, since most of the methodology has been available for years, but owing to the explosion in the amount of data at hand (the era of big data). The typical applications in management are usually related to Customer Relationship Management (CRM): market basket analysis, churn modelling, credit scoring, etc.

Data mining was born in the computer science field, as the analytic step of the so called **knowledge discovery in databases** (KDD). Although the acronym KDD is still used by organizations and conferences, it is mostly unknown in the business world. In the opposite direction, the expression **data scientist** is getting popular in job descriptions, referred to a mix of data mining proficiency and a background of programming languages and data bases.

**Machine learning** (ML) was born in the (first) golden age of **artificial intelligence** (AI). The objective was the study of systems that could learn from data, but many of the methods were the same as those of data mining. Nowadays, machine learning is also popular in the business world, due to the increasing interest of giants like IBM, Google, Baidu, etc and artificial intelligence is a the hot topic for tech companies.

Data mining textbooks (e.g. Larose, 2005) describe data mining methods that apply to data in structured form, that is, to data sets in tabular form, with rows and columns. The rows correspond to **instances** (also called observations, cases and records), such as individuals, companies or transactions. The columns correspond to **attributes** (also called variables and fields). Typically, the attributes are either **numeric**, as the amount paid in a transaction, or **categorical**, as gender. Nevertheless, there are also methods for dealing with string (text) data and dates. Categorical attributes are frequently managed through **dummies**, or attributes with 1/0 values.

In data mining, the main job is **prediction**, that is, to describe one attribute (Y) in terms of the other attributes (X's). Typically, the predictive model is first developed in a data set called the **training set** and later applied to other data. When a second data set is used to **validate** the model, it is called the **test set**. In the data mining context, the term **regression** applies to the prediction of a numeric attribute, and **classification** to the prediction of a nominal attribute. In an example of regression, we may try to predict the price of a house from a set of attributes of this house. In one of classification, to predict whether a customer is going to quit or not, from his/her demographics plus some measures of customer activity.

### Software for data mining

From the perspective of how the user interacts with the data mining software, there are three possibilities: (a) conventional menus, (b) programming code and (c) visual programming, based on flow charts which are a graphical translation of code. This course is based on code, which is what data scientists mostly use. It uses the **R statistical language**, which is, currently, the leading choice of data scientists. Just a few years ago, data mining textbooks, such as Larose (2005), or Nisbet *et al*. (2009), used Clementine (visual programming), Statistica (menus) and SAS Enterprise Miner (menus). But, nowadays, books are usually based on R, **Python** or (less frequently) **Java**, and the examples include code.

This section contains brief comments about other choices, at the personal computer level, different
from the one made in this course. Among the old stat packages, the main contenders are:

* SPSS (Statistical Package for the Social Sciences) is one of the oldest statistical packages. In 1998, SPSS Inc. adquired Clementine, the first data mining tool using visual programming in a graphical interface. In 2009, SPSS Inc. was adquired by IBM, which now offers updated versions of SPSS and Clementine under the names of SPSS Statistics and **SPSS Modeler**, respectively.

* SAS (Statistical Analysis System) is also a veteran among the statistical packages. It has modular structure, with so many modules that is difficult to keep track. One of the modules is **SAS Enterprise Miner**, which provides a pack of cases, explained with detail.

* **Statistica** is also a statistical package, not as old as SPSS and SAS, which has been increasingly emphasizing data mining resources. As SAS, it is modular, with a lot of modules.

There is also plenty of choice among the data mining suites:

* **Weka** (Waikato Environment for Knowledge Analysis) is the best-known open-source data mining environment (see Witten *et al*., 2011, for details). It is written in Java (versions for Windows and Macintosh). Advanced users can access its components through Java programming or through a command-line interface. For the rest of us, Weka provides a **graphical user interface** (GUI), the **Weka Explorer**, in which the user can test different models. Weka's community has also developed a set of extensions covering diverse areas, such as text mining, visualization, bioinformatics, and grid computing. Like R in statistics, Weka has been for years the reference in the machine learning community, attracting a number of users and developers. Some of the Weka algorithms can be called from R, through the package **RWeka**.

* **Rapid Miner**, formerly YALE (Yet Another Learning Environment), has been, until recently, the most popular environment for data mining. It is written in Java and can extend its library of algorithms with those provided by R and Weka. It uses visual programming, but the programs are accessible as XML files. Besides the commercial versions, a starter version of Rapid Miner Studio can be downloaded for free.

* **KNIME** (Konstanz Information Miner) is a nicely designed data mining suite which runs inside the Eclipse development environment, similar to that of Rapid Miner, but better, to my taste. It is also written in Java and can also extend its library of built-in algorithms with those provided by Weka and  R.

* **scikit-learn** may be the choice for those who speak Python, a popular language which is gaining ground among data scientists. It comes with excellent on-line documentation (for pythonistas).

### Introduction to R

R is a language which comes with an environment for computing and graphics, available for both Windows and Macintosh. It includes an extensive variety of techniques for statistical testing, predictive modelling and data visualization. R can be extended by hundreds of additional packages available at the **Comprehensive R Archive Network** (CRAN), which cover virtually every aspect of statistical data analysis and machine learning. As a rule, I do not use one of these packages unless it makes a real difference. 

There are many books for learning about R, but most of them are too statistically-oriented, so they may not be for you. A popular choice, with a broad perspective, is Teetor (2011). Also popular, and a bit more ambitious, is Adler (2012).

R has been gaining acceptance in the business intelligence industry in the last years: one can use R resources in Oracle, Microsoft Azure Cloud, SAP HANA, etc. It has been adopted as the default analytic tool by many well known companies such as Google, which has even written an R Style Book for its programmers.

R provides a GUI, which, called the **console**, in which we can type (or paste) our code. The console works a bit different in Macintosh and Windows. In the Windows console, what you type is in red and the R response in blue. In Macintosh, we type in blue and the response comes in black. When R is ready for our code, the console shows a **prompt** which is the symbol "greater than" (>). With the `Return` key, we finish a line of code, which is usually interpreted as request for execution. But R can detect that your input is not finished, and then it waits for more input showing a different prompt, the symbol "plus" (+). 

In an **R Markdown** document like the one that you are reading, this is usually seen as follows.

````{r}
2 + 2
```

The R console is not user-friendly, so you will probably prefer to work in an interactive developer environment (IDE). **RStudio** is the leading choice and, nowadays, most R coders prefer RStudio to the console. In RStudio, you have the console plus other windows that may help you to organize your task.

### Objects in R

R is **object-oriented**, with many classes of objects. I comment here briefly some classes which will appear in the analysis of the examples of this course. First, we have **vectors**. A vector is an ordered collection of elements which are all of the same type. Vectors can be **numeric**, **factors** (explained later), **character** (string), **logical** (TRUE/FALSE) or of other types not discussed in this course. The following three examples are numeric (`x`), character (`y`) and logic (`z`), respectively.

````{r}
x <- 1:10
x
y <- c("Messi", "Neymar", "Cristiano")
y
z <- x > 5
z
````

Comments on these examples:

* The expression `c(a,b)` packs the elements `a` and `b` as the terms of a vector. This is only possible if they are of the same type. 

* The quote marks indicate character type. 

* An expression like `x > 5` is translated as a logical vector with one term for each term of `x`. 

The first term of the vector `x` can be extracted as `x[1]`, the second term as `x[2]`, etc. **Matrices** are like vectors, but two-dimensional. They can be numeric, character or logical. The terms of a matrix are identified by two indexes. For instance, `A[2,3]` is the term in the second row, third column.

```{r}
A <- matrix(1:24, nrow=4)
A
A[2,3]
```

A **data frame** (a data set) is a set of vectors (presented as columns). These vectors can have different type, but the same length. A vector of a data frame are identified as `dataframe$variable`. Rows and columns of a data frame are identified as in a matrix.


```{r}
df <- data.frame(v1=1:10, v2=10:1, v3=rep(-1,10))
df
df$v1
```

A **factor** is a numeric vector in which the values have labels, called **levels**. Factors are very natural to statisticians (stat packages, like SPSS or Stata use similar systems), but look weird to computer engineers, since programming languages don't have them.

Extracting parts of R objects is called is called **subsetting**. Vectors, matrices and data frames can be subsetted in an easy way. Some examples follow. 

````{r}
x[1:3]
x[x>=5]
A[1:2,3:6]
df[,-3]
df[df$v1<df$v2,]
```

R is a fully functional language. The real power of R lies in defining the operations that you wish to perform as **functions**, so they can be applied many times. For instance, import and export are usually managed by read/write functions. A simple example follows.

```{r}
f <- function(x) 1/(1+x^2)
f(1)
```

You can replace all the "arrows" (<-) by equal signs, and nothing will change. Nevertheless, it is recommended, to the beginner, to use the arrow system, to avoid mistakes. `x <- 2 + 2` is read `assign("x", 2+2)`. We can also write `2 + 2 -> x`, but `2 + 2 <- x` does not make sense. The equal sign is read as  <- (as in any programming language).

### Importing data to R

Data sets can be imported to R data frames from many formats, typically from text files, with the `read.table` function. For **csv files**, there is a special function `read.csv`. The default of `read.csv` is reading the first line of the file as the names of the variables. 

To capture the data, we have to specify a **path** in our computer or a URL. Let me illustrate with the following code, which imports a csv file containing daily OCHL (Open/Close/High/Low) data for the CNX 500 index, from 2005-01-01 to 2014-12-31, extracted from Yahoo Finance India. I perform some checks on the data frame.

```{r}
cnx <- read.csv("http://real-chart.finance.yahoo.com/table.csv?s=%5ECRSLDX&a=00&b=01&c=2005&d=11&e=31&f=2014&g=d&ignore=.csv")
dim(cnx)
head(cnx)
tail(cnx)
```

The structure of an R object can be explored with the function `str`. Note that, in this case, the variable `Date` has been imported as a factor. This is the default for importing string data in R.

````{r}
str(cnx)
```

The funtion `summary` works in different ways in objects of different nature. For numeric variables, it produces some summary statistics.

````{r}
summary(cnx)
```

As an illustration, the returns of the adjusted closing price are calculated below. The function `hist` allows exploring the distribution. 

````{r}
return <- cnx$Adj.Close[-1]/cnx$Adj.Close[-1828] - 1
hist(return, main="CNX 500 Adjusted Close", xlab="Daily returns", breaks=20)
```


### References

1. J Adler (2012), *R in a Nutshell*, O'Reilly. 

2. DT Larose (2005), *Discovering Knowledge in Data*, Wiley.

3. V Mayer-Schönberger & K Cukier (2012), *Big Data*, John Murray.

4. R Nisbet, J Elder & G Miner (2009), *Handbook of Statistical Analysis & Data Mining*, Academic Press. 

5. F Provost & T Fawcett (2013), *Data Science for Business --- What You Need to Know About Data Mining and Data-Analytic Thinking*, O'Reilly. 

6. P Teetor (2011), *R Cookbook*, O'Reilly.

7. IH Witten, E Frank & MA Hall (2011), *Data Mining: Practical Machine Learning Tools and Techniques*, Morgan Kaufmann.
